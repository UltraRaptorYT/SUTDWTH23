{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\51703\\Documents\\GitHub\\SUTDWTH23\\env\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import openai\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from collections import deque\n",
    "from typing import Dict, List, Optional, Any\n",
    "\n",
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import BaseLLM\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chains.base import Chain\n",
    "# Langchain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, LLMChain ,LLMCheckerChain\n",
    "from langchain.callbacks import wandb_tracing_enabled\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "from typing import Optional\n",
    "from langchain.chains import SimpleSequentialChain ,SequentialChain\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.agents import AgentType, initialize_agent,AgentExecutor\n",
    "from langchain.tools import tool\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "# wandb\n",
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from the .env file\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Access the variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "PINECONE_ENVIRONMENT= os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "# wandb\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"false\"\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'test_llm_pinecone.ipynb'\n",
    "# here we are configuring the wandb project name\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Singlife\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'constructor',\n",
       " 'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'],\n",
       " 'kwargs': {'model_name': 'gpt-3.5-turbo-0613',\n",
       "  'temperature': 0.0,\n",
       "  'openai_api_key': {'lc': 1, 'type': 'secret', 'id': ['OPENAI_API_KEY']}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt-3.5-turbo-0613\"\n",
    "temperature = 0.0\n",
    "llm = ChatOpenAI(model_name=model_name, temperature=temperature)\n",
    "llm.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema= {\n",
    "    \"name\": \"estimate expiration date\",\n",
    "    \"description\": \"Given ingrediants and their Quantity, estimate the expiration date of each ingrediant\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"list_of_ingrediants\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"Name\": { \"type\": \"string\" },\n",
    "            \"Quantity\": { \"type\": \"integer\" },\n",
    "            \"Expiration\": { \"type\": \"string\", \"format\": \"date\" }\n",
    "          },\n",
    "          \"required\": [\"Name\", \"Quantity\", \"Expiration\"]\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"list_of_ingrediants\"]\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an expiratity date estimator, given this list of inputs of food ingredients, estimate based on today date 2023-08-26 when the food ingredients will expire.\\nmy inventory of ingrediants:{ingredients}\"\"\",\n",
    "    input_variables= [\"ingredients\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = {\n",
    "    \"Egg\":12,\n",
    "    \"Apple\":5,\n",
    "    \"Milk\":2,\n",
    "    \"Bread\":4,\n",
    "    \"Butter\":3,\n",
    "    \"Cheese\":2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expire_chain = create_structured_output_chain(json_schema, llm, video_prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an expiratity date estimator, given this list of inputs of food ingredients, estimate based on today date 2023-08-26 when the food ingredients will expire.\n",
      "my inventory of ingrediants: {'Egg': 12, 'Apple': 5, 'Milk': 2, 'Bread': 4, 'Butter': 3, 'Cheese': 2}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'list_of_ingrediants': [{'Name': 'Egg',\n",
       "   'Quantity': 12,\n",
       "   'Expiration': '2023-09-02'},\n",
       "  {'Name': 'Apple', 'Quantity': 5, 'Expiration': '2023-08-30'},\n",
       "  {'Name': 'Milk', 'Quantity': 2, 'Expiration': '2023-08-28'},\n",
       "  {'Name': 'Bread', 'Quantity': 4, 'Expiration': '2023-08-29'},\n",
       "  {'Name': 'Butter', 'Quantity': 3, 'Expiration': '2023-08-28'},\n",
       "  {'Name': 'Cheese', 'Quantity': 2, 'Expiration': '2023-08-28'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expire_chain.run(ingredients = ingredients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
